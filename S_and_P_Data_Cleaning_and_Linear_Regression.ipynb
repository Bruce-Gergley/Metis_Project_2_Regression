{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Jupyter Notebook has the code to construct linear regression and polynomial regression models on the S & P\n",
    "# data that was scraped in the previous Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports python libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.core.display import display, HTML\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block sets the display parameters for pandas dataframes in this notebook\n",
    "\n",
    "pd.set_option('display.max_columns', 63)\n",
    "pd.set_option('display.max_rows', 505)\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block reads the pickle file from the previous Jupyter notebook to recreate the full dataframe\n",
    "\n",
    "# If you want to do regression analysis for multiple different time spans, you can run the scrape multiple times,\n",
    "# and give each dataframe pkl file a different name (advisably a name indicating the start and end dates)\n",
    "\n",
    "# Set the name of the file to match the dataframe you want to analyze\n",
    "\n",
    "with open('Full_S_and_P_DF.pkl', 'rb') as read_file:\n",
    "    Full_S_and_P_DF = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the dataframe, de-commentify the code line below\n",
    "\n",
    "#display(Full_S_and_P_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block creates a function to remove commas from a string/object (will help convert it into a float)\n",
    "\n",
    "def NoCommas(string):\n",
    "    \n",
    "    Output = \"\"\n",
    "    String_Index = 0\n",
    "    \n",
    "    while(String_Index < len(string)):\n",
    "        if(string[String_Index] == \",\"):\n",
    "            pass\n",
    "        else:\n",
    "            Output = Output + str(string[String_Index])\n",
    "            \n",
    "        String_Index += 1\n",
    "        \n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block converts numbers saved as non-float values to float variables for the financial data\n",
    "# The Industry one-hot encoded variable columns end at 'Materials' and the financial variables start right after\n",
    "\n",
    "List_of_Columns = list(Full_S_and_P_DF.columns)\n",
    "\n",
    "Row_Index = 0\n",
    "Column_Index_Start = (List_of_Columns.index('Materials') + 1)\n",
    "Column_Index = Column_Index_Start\n",
    "Number_Of_Dashes = 0\n",
    "Number_Of_Empty_Strings = 0\n",
    "Changed_To_Float = 0\n",
    "\n",
    "while(Column_Index < len(List_of_Columns)):\n",
    "    \n",
    "    Row_Index = 0\n",
    "    \n",
    "    Column = List_of_Columns[Column_Index]\n",
    "\n",
    "    while(Row_Index < len(Full_S_and_P_DF)):\n",
    "        \n",
    "        if(pd.isna(Full_S_and_P_DF[Column][Row_Index])):\n",
    "            pass\n",
    "        elif(Full_S_and_P_DF[Column][Row_Index] == \"-\"):\n",
    "            pass\n",
    "        elif(Full_S_and_P_DF[Column][Row_Index] == \"\"):\n",
    "            pass\n",
    "        elif(type(Full_S_and_P_DF[Column][Row_Index]) is float):\n",
    "            pass\n",
    "        else:\n",
    "            Full_S_and_P_DF[Column][Row_Index] = float(NoCommas(Full_S_and_P_DF[Column][Row_Index]))\n",
    "            #Changed_To_Float += 1\n",
    "            #if(Changed_To_Float < 30):\n",
    "                #print(Column, Row_Index, (Full_S_and_P_DF[Column][Row_Index]), type(Full_S_and_P_DF[Column][Row_Index]))\n",
    "\n",
    "        Row_Index += 1\n",
    "\n",
    "    Column_Index += 1\n",
    "    \n",
    "# If you want to see the first 30 values converted to float, de-commentify the commented lines in the else statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block creates a dictionary to check how many float values are in each column of financial data\n",
    "\n",
    "Row_Index = 0\n",
    "Column_Index = Column_Index_Start\n",
    "\n",
    "Column_Dict = defaultdict(int)\n",
    "\n",
    "while(Column_Index < len(List_of_Columns)):\n",
    "    \n",
    "    Row_Index = 0\n",
    "    Floats_In_Column = 0\n",
    "    \n",
    "    Column = List_of_Columns[Column_Index]\n",
    "\n",
    "    while(Row_Index < len(Full_S_and_P_DF)):\n",
    "        \n",
    "        if(pd.isna(Full_S_and_P_DF[Column][Row_Index])):\n",
    "            pass\n",
    "        elif(Full_S_and_P_DF[Column][Row_Index] == \"-\"):\n",
    "            pass\n",
    "        elif(Full_S_and_P_DF[Column][Row_Index] == \"\"):\n",
    "            pass\n",
    "        elif(type(Full_S_and_P_DF[Column][Row_Index]) is float):\n",
    "            Floats_In_Column += 1\n",
    "        else:\n",
    "            Full_S_and_P_DF[Column][Row_Index] = float(NoCommas(Full_S_and_P_DF[Column][Row_Index]))\n",
    "            Floats_In_Column += 1\n",
    "\n",
    "        Row_Index += 1\n",
    "    \n",
    "    Column_Dict[Column] = Floats_In_Column\n",
    "    Column_Index += 1\n",
    "\n",
    "# To see the dictionary, de-commentify the print statement below\n",
    "#print(Column_Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block drops columns with no float values\n",
    "\n",
    "for Column in Column_Dict:\n",
    "    if(Column_Dict[Column] == 0):\n",
    "        Full_S_and_P_DF = Full_S_and_P_DF.drop([Column], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the information on the columns and data types for this dataframe, de-commentify the code line below\n",
    "\n",
    "#Full_S_and_P_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The financial data features scrapped from Income Statements inevitably contain a high degree of colinearity \n",
    "# This is because some fields are used to calculate other fields\n",
    "# For most companies, the format is:\n",
    "\n",
    "# Total Revenue - Cost of Revenue = Gross Profit\n",
    "# Gross Profit - Operating Expenses = Operating Income\n",
    "# Operating Income + or - (Non-Operating Expenses/Income from Interest, Capital Gains/Loses, etc.) = Pre-Tax Income\n",
    "# Pre-Tax Income - (Tax Provision or Income Tax Expense) = Net Income\n",
    "\n",
    "# These fields are populated for vast majority of companies in this data set\n",
    "# Some companies have null Gross Profit or Operating Income fields (particularly financial or banking companies)\n",
    "# The missing fields can be substituted with pseudo-values based on Total Revenue and Pre-Tax Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block creates a new dataframe with selected fields in order to perform regression analysis \n",
    "\n",
    "Regression_DF_1 = Full_S_and_P_DF.filter(['Weight', 'Information Technology', 'Consumer Discretionary',\n",
    "                               'Financials','Health Care', 'Consumer Staples', 'Energy', \n",
    "                               'Telecommunication Services', 'Industrials', 'Utilities','Real Estate', \n",
    "                               'Materials', 'Total Revenue', 'Gross Profit', 'Operating Income', 'Pretax Income',\n",
    "                               'Net Income Common Stockholders', 'Percent Increase']).copy()\n",
    "\n",
    "Regression_DF_1['Percent Increase'] = (100 * Regression_DF_1['Percent Increase'])\n",
    "\n",
    "# To view this dataframe, de-commentify the code line below\n",
    "\n",
    "#display(Regression_DF_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block drops rows that have no value for the target column (Percent Increase)\n",
    "# It also drops rows that have no value for the Total Revenue, Pretax Income, or Net Income fields\n",
    "\n",
    "Row_Index = 0\n",
    "\n",
    "while(Row_Index < len(Regression_DF_1)):\n",
    "    \n",
    "    if(np.isnan(Regression_DF_1[\"Total Revenue\"][Row_Index]) == True):\n",
    "        Regression_DF_1.drop(Row_Index, axis=0, inplace=True)\n",
    "    elif(np.isnan(Regression_DF_1[\"Pretax Income\"][Row_Index]) == True):\n",
    "        Regression_DF_1.drop(Row_Index, axis=0, inplace=True)\n",
    "    elif(np.isnan(Regression_DF_1[\"Net Income Common Stockholders\"][Row_Index]) == True):\n",
    "        Regression_DF_1.drop(Row_Index, axis=0, inplace=True)\n",
    "    elif(np.isnan(Regression_DF_1[\"Percent Increase\"][Row_Index]) == True):\n",
    "        Regression_DF_1.drop(Row_Index, axis=0, inplace=True)\n",
    "    \n",
    "    Row_Index += 1\n",
    "    \n",
    "# To view how many rows are left after some are dropped, de-commentify the code line below\n",
    "\n",
    "#print(len(Regression_DF_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block resets the index so there are no index numbers skipped for the dropped rows\n",
    "\n",
    "Regression_DF_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the dataframe, de-commentify the code line below\n",
    "\n",
    "#display(Regression_DF_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block creates lists determines the relative proportions of Cost of Revenue, Operating Expenses, and \n",
    "# Other Expenses as a proportion of total expenses going from Gross Revenue to Net Income\n",
    "# This will be used to fill in pseudo-values for \"Gross Profit\" and \"Operating Income\" in rows missing those fields\n",
    "\n",
    "Cost_Of_Revenue_Proportion_List = []\n",
    "Operating_Expenses_Proportion_List = []\n",
    "Other_Proportion_List = []\n",
    "\n",
    "Row_Index = 0\n",
    "\n",
    "while(Row_Index < len(Regression_DF_1)):\n",
    "    \n",
    "    if((type(Regression_DF_1[\"Gross Profit\"][Row_Index]) is float) and (np.isnan(Regression_DF_1[\"Gross Profit\"][Row_Index]) == False)):\n",
    "        if((type(Regression_DF_1[\"Operating Income\"][Row_Index]) is float) and (np.isnan(Regression_DF_1[\"Operating Income\"][Row_Index]) == False)):\n",
    "            \n",
    "            Total_Rev = Regression_DF_1[\"Total Revenue\"][Row_Index]\n",
    "            \n",
    "            Total_Pre_Tax_Costs = Total_Rev - Regression_DF_1[\"Pretax Income\"][Row_Index]\n",
    "            Total_Other = Regression_DF_1[\"Operating Income\"][Row_Index] - Regression_DF_1[\"Pretax Income\"][Row_Index]\n",
    "            Total_Operating_Expenses = Regression_DF_1[\"Gross Profit\"][Row_Index] - Regression_DF_1[\"Operating Income\"][Row_Index]\n",
    "            Total_Cost_Of_Revenue = Total_Rev - Regression_DF_1[\"Gross Profit\"][Row_Index]\n",
    "            \n",
    "            Cost_Of_Revenue_Proportion_List.append((Total_Cost_Of_Revenue/Total_Pre_Tax_Costs))\n",
    "            \n",
    "            Operating_Expenses_Proportion_List.append((Total_Operating_Expenses/Total_Pre_Tax_Costs))\n",
    "            \n",
    "            Other_Proportion_List.append((Total_Other/Total_Pre_Tax_Costs))\n",
    "            \n",
    "    Row_Index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block checks how many rows had values for gross profit and operating expense\n",
    "# All 3 printed values should be equal\n",
    "# To check this, de-commentify the print stateents below\n",
    "\n",
    "#print(len(Cost_Of_Revenue_Proportion_List))\n",
    "#print(len(Operating_Expenses_Proportion_List))\n",
    "#print(len(Other_Proportion_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block calculates the average of each cost/expense category as a percent of total costs/expenses\n",
    "# To view each proportion de-commentify the print statements\n",
    "\n",
    "Average_Cost_Of_Revenue_Proportion = (sum(Cost_Of_Revenue_Proportion_List)/len(Cost_Of_Revenue_Proportion_List))\n",
    "#print(Average_Cost_Of_Revenue_Proportion)\n",
    "Average_Operating_Expenses_Proportion = (sum(Operating_Expenses_Proportion_List)/len(Operating_Expenses_Proportion_List))\n",
    "#print(Average_Operating_Expenses_Proportion)\n",
    "Average_Other_Proportion = (sum(Other_Proportion_List)/len(Other_Proportion_List))\n",
    "#print(Average_Other_Proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block checks to make sure the average proportions add up to approximately 1\n",
    "# To check this sum, and make sure it is approximately 1, de-commentify the print statement below\n",
    "\n",
    "#print((Average_Cost_Of_Revenue_Proportion + Average_Operating_Expenses_Proportion + Average_Other_Proportion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block fills in pseudo-values for \"Gross Profit\" and \"Operating Income\" where those are missing\n",
    "\n",
    "Row_Index = 0\n",
    "\n",
    "while(Row_Index < len(Regression_DF_1)):\n",
    "    \n",
    "    Total_Pre_Tax_Cost = Regression_DF_1[\"Total Revenue\"][Row_Index] - Regression_DF_1[\"Pretax Income\"][Row_Index]\n",
    "    \n",
    "    if((type(Regression_DF_1[\"Gross Profit\"][Row_Index]) is str) or (np.isnan(Regression_DF_1[\"Gross Profit\"][Row_Index]) == True)):\n",
    "        \n",
    "        Pseudo_Cost_Of_Revenue = (Total_Pre_Tax_Cost * Average_Cost_Of_Revenue_Proportion)\n",
    "        Regression_DF_1[\"Gross Profit\"][Row_Index] = Regression_DF_1[\"Total Revenue\"][Row_Index] - Pseudo_Cost_Of_Revenue\n",
    "        \n",
    "    if((type(Regression_DF_1[\"Operating Income\"][Row_Index]) is str) or (np.isnan(Regression_DF_1[\"Operating Income\"][Row_Index]) == True)):\n",
    "        \n",
    "        Pseudo_Operating_Expenses = (Total_Pre_Tax_Cost * Average_Operating_Expenses_Proportion)\n",
    "        Regression_DF_1[\"Operating Income\"][Row_Index] = Regression_DF_1[\"Gross Profit\"][Row_Index] - Pseudo_Operating_Expenses\n",
    "        \n",
    "    Row_Index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the dataframe, de-commentify the code line below\n",
    "\n",
    "#display(Regression_DF_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view dataframe column and value type information, de-commentify the code line below\n",
    "# If some columns have non-numeric objects data types, they must be converted to numeric\n",
    "\n",
    "#Regression_DF_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block converts object variables to floats\n",
    "\n",
    "Regression_1_Columns = list(Regression_DF_1.columns)\n",
    "\n",
    "Column_Index = Regression_1_Columns.index(\"Total Revenue\")\n",
    "\n",
    "while(Column_Index < len(Regression_1_Columns)):\n",
    "    \n",
    "    Column = Regression_1_Columns[Column_Index]\n",
    "    Regression_DF_1[Column] = pd.to_numeric(Regression_DF_1[Column], errors='coerce')\n",
    "    \n",
    "    Column_Index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view dataframe column and value type information, de-commentify the code line below\n",
    "# All columns should now have numeric data types\n",
    "\n",
    "#Regression_DF_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view correlation strength between variables, de-commentify the data frame below\n",
    "\n",
    "#Regression_DF_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view agegate stats for each column, de-commentify the data frame below\n",
    "\n",
    "#Regression_DF_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code blocks begins to create linear regression models\n",
    "# The following 5 code blocks are for first linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block identifies the features and target for a linear regression\n",
    "# This code block also splits the data into test and train segments\n",
    "\n",
    "# Features\n",
    "X_1 = Regression_DF_1.loc[:, 'Weight':'Net Income Common Stockholders']\n",
    "\n",
    "# Target\n",
    "Y_1 = Regression_DF_1['Percent Increase']\n",
    "\n",
    "# Split into test and train data (80% Train Data)\n",
    "X_Train_1, X_Test_1, Y_Train_1, Y_Test_1 = train_test_split(X_1, Y_1, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block trains and scores a linear regression model on the training segment of the data\n",
    "# It is scored using the R Squared metric\n",
    "\n",
    "# Create an empty model\n",
    "lr_1 = LinearRegression()\n",
    "\n",
    "# Fit on train\n",
    "lr_1.fit(X_Train_1, Y_Train_1)\n",
    "\n",
    "# Score on train\n",
    "lr_1.score(X_Train_1, Y_Train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block scores the model on the test data\n",
    "\n",
    "# Score on test\n",
    "lr_1.score(X_Test_1, Y_Test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the coeficient array for this regression, de-commentify the line of code below\n",
    "\n",
    "#lr_1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the Y intercept array for this regression, de-commentify the line of code below\n",
    "\n",
    "#lr_1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code blocks use the same feature columns and target as the first linear regression\n",
    "# This next regression however allows for polynomial features\n",
    "# This allows for a potentially better R-Squared score, but increases the risk of overfitting to the train data\n",
    "# Regularization can help with the overfitting problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block introduces polynomial features \n",
    "\n",
    "pf_1 = PolynomialFeatures(degree=2)\n",
    "\n",
    "pf_1.fit(X_1)\n",
    "\n",
    "X_1_Transformed = pf_1.transform(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block performs a test-train split\n",
    "\n",
    "X_1_Transformed_Train, X_1_Transformed_Test, Y_Train_1_PF, Y_Test_1_PF = train_test_split(X_1_Transformed, Y_1, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block fits and scores a polynomial regression on the train data\n",
    "\n",
    "lr_1_Transformed = LinearRegression()\n",
    "\n",
    "lr_1_Transformed.fit(X_1_Transformed_Train, Y_Train_1_PF)\n",
    "\n",
    "lr_1_Transformed.score(X_1_Transformed_Train, Y_Train_1_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block scores the polynomial regression on the test data\n",
    "\n",
    "lr_1_Transformed.score(X_1_Transformed_Test, Y_Test_1_PF)\n",
    "\n",
    "# Non-regularized polynomial features fails to produce a better test R^2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next few code blocks apply regularization to the polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block ensures (using normalization) that data columns of the features are on the are same scale\n",
    "# The normalized values of a column should have a mean of 0 and standard deviation of 1\n",
    "\n",
    "std = StandardScaler()\n",
    "std.fit(X_1_Transformed)\n",
    "X_1_Transformed_Train_Scaled = std.transform(X_1_Transformed_Train)\n",
    "X_1_Transformed_Test_Scaled = std.transform(X_1_Transformed_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next 3 code blocks apply Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block finds a good value for the Alpha parameter for Ridge regularization\n",
    "# To view the progress of optimizing alpha values, de-commentify the print statements\n",
    "\n",
    "Alpha = 1\n",
    "Prior_Alpha = 0\n",
    "Best_Alpha_Passed = False\n",
    "Iterations = 0\n",
    "\n",
    "Current_Test_Score = 0\n",
    "Prior_Test_Score = 0\n",
    "\n",
    "#print(\"Alpha   |      Test Score\")\n",
    "#print(\"________|________________\")\n",
    "\n",
    "while((Iterations < 2) or (Best_Alpha_Passed == False)):\n",
    "    \n",
    "    if(Iterations > 0):\n",
    "        Prior_Test_Score = Current_Test_Score\n",
    "        Prior_Alpha = Alpha\n",
    "        Alpha = (2 * Alpha)\n",
    "\n",
    "    lr_1_Transformed_Ridge = Ridge(alpha = Alpha)\n",
    "    lr_1_Transformed_Ridge.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    Train_Score = lr_1_Transformed_Ridge.score(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    \n",
    "    Current_Test_Score = lr_1_Transformed_Ridge.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)\n",
    "    \n",
    "    #print(Alpha, \":         \", Current_Test_Score)\n",
    "    \n",
    "    if(Iterations > 0):\n",
    "        if(Current_Test_Score < Prior_Test_Score):\n",
    "            Best_Alpha_Passed = True    \n",
    "            \n",
    "    Iterations += 1\n",
    "    \n",
    "Low_Alpha = max(0, ((Prior_Alpha/2) - 1))\n",
    "High_Alpha = Alpha\n",
    "Mid_Alpha = ((Low_Alpha + High_Alpha)/2)\n",
    "Increment = (High_Alpha - Mid_Alpha)\n",
    "\n",
    "while(Increment > 0.01):\n",
    "    \n",
    "    lr_1_Transformed_Ridge = Ridge(alpha = Low_Alpha)\n",
    "    lr_1_Transformed_Ridge.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    Low_Alpha_Test_Score = lr_1_Transformed_Ridge.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)\n",
    "    \n",
    "    lr_1_Transformed_Ridge = Ridge(alpha = Mid_Alpha)\n",
    "    lr_1_Transformed_Ridge.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    Mid_Alpha_Test_Score = lr_1_Transformed_Ridge.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)\n",
    "    \n",
    "    #print(Mid_Alpha, \":         \", Mid_Alpha_Test_Score)\n",
    "    \n",
    "    lr_1_Transformed_Ridge = Ridge(alpha = High_Alpha)\n",
    "    lr_1_Transformed_Ridge.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    High_Alpha_Test_Score = lr_1_Transformed_Ridge.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)\n",
    "    \n",
    "    if(High_Alpha_Test_Score > Low_Alpha_Test_Score):\n",
    "        if(High_Alpha_Test_Score <= Mid_Alpha_Test_Score):\n",
    "            Increment = (Increment/2)\n",
    "        Mid_Alpha += Increment\n",
    "    elif(High_Alpha_Test_Score < Low_Alpha_Test_Score):\n",
    "        if(Low_Alpha_Test_Score <= Mid_Alpha_Test_Score):\n",
    "            Increment = (Increment/2)\n",
    "        Mid_Alpha -= Increment\n",
    "    else:\n",
    "        Increment = (Increment/2)\n",
    "        \n",
    "    Low_Alpha = (Mid_Alpha - Increment)\n",
    "    High_Alpha = (Mid_Alpha + Increment)\n",
    "    \n",
    "Ridge_Alpha_1 = Mid_Alpha\n",
    "#print(\"________________________________\")\n",
    "#print(\"Final Ridge Alpha:\", Ridge_Alpha_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block uses the Alpha parameter just found to apply Ridge regularization\n",
    "\n",
    "lr_1_Transformed_Ridge = Ridge(alpha = Ridge_Alpha_1)\n",
    "lr_1_Transformed_Ridge.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "lr_1_Transformed_Ridge.score(X_1_Transformed_Train_Scaled, Y_Train_1_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block scores the regularized model on the test data\n",
    "\n",
    "lr_1_Transformed_Ridge.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next 3 code blocks apply Lasso Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block finds a good value for the Alpha parameter for Lasso regularization\n",
    "# To view the progress of optimizing alpha values, de-commentify the print statements\n",
    "\n",
    "Alpha = 1\n",
    "Prior_Alpha = 0\n",
    "Best_Alpha_Passed = False\n",
    "Iterations = 0\n",
    "\n",
    "Current_Test_Score = 0\n",
    "Prior_Test_Score = 0\n",
    "\n",
    "#print(\"Alpha   |      Test Score\")\n",
    "#print(\"________|________________\")\n",
    "\n",
    "while((Iterations < 2) or (Best_Alpha_Passed == False)):\n",
    "    \n",
    "    if(Iterations > 0):\n",
    "        Prior_Test_Score = Current_Test_Score\n",
    "        Prior_Alpha = Alpha\n",
    "        Alpha = (2 * Alpha)\n",
    "\n",
    "    lr_1_Transformed_Lasso = Lasso(alpha = Alpha)\n",
    "    lr_1_Transformed_Lasso.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    Train_Score = lr_1_Transformed_Lasso.score(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    \n",
    "    Current_Test_Score = lr_1_Transformed_Lasso.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)\n",
    "    \n",
    "    #print(Alpha, \":         \", Current_Test_Score)\n",
    "    \n",
    "    if(Iterations > 0):\n",
    "        if(Current_Test_Score < Prior_Test_Score):\n",
    "            Best_Alpha_Passed = True    \n",
    "            \n",
    "    Iterations += 1\n",
    "    \n",
    "Low_Alpha = max(0, ((Prior_Alpha/2) - 1))\n",
    "High_Alpha = Alpha\n",
    "Mid_Alpha = ((Low_Alpha + High_Alpha)/2)\n",
    "Increment = (High_Alpha - Mid_Alpha)\n",
    "\n",
    "while(Increment > 0.01):\n",
    "    \n",
    "    lr_1_Transformed_Lasso = Lasso(alpha = Low_Alpha)\n",
    "    lr_1_Transformed_Lasso.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    Low_Alpha_Test_Score = lr_1_Transformed_Lasso.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)\n",
    "    \n",
    "    lr_1_Transformed_Lasso = Lasso(alpha = Mid_Alpha)\n",
    "    lr_1_Transformed_Lasso.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    Mid_Alpha_Test_Score = lr_1_Transformed_Lasso.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)\n",
    "    \n",
    "    #print(Mid_Alpha, \":         \", Mid_Alpha_Test_Score)\n",
    "    \n",
    "    lr_1_Transformed_Lasso = Lasso(alpha = High_Alpha)\n",
    "    lr_1_Transformed_Lasso.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "    High_Alpha_Test_Score = lr_1_Transformed_Lasso.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)\n",
    "    \n",
    "    if(High_Alpha_Test_Score > Low_Alpha_Test_Score):\n",
    "        if(High_Alpha_Test_Score <= Mid_Alpha_Test_Score):\n",
    "            Increment = (Increment/2)\n",
    "        Mid_Alpha += Increment\n",
    "    elif(High_Alpha_Test_Score < Low_Alpha_Test_Score):\n",
    "        if(Low_Alpha_Test_Score <= Mid_Alpha_Test_Score):\n",
    "            Increment = (Increment/2)\n",
    "        Mid_Alpha -= Increment\n",
    "    else:\n",
    "        Increment = (Increment/2)\n",
    "        \n",
    "    Low_Alpha = (Mid_Alpha - Increment)\n",
    "    High_Alpha = (Mid_Alpha + Increment)\n",
    "    \n",
    "\n",
    "Lasso_Alpha_1 = Mid_Alpha\n",
    "#print(\"________________________________\")\n",
    "#print(\"Final Ridge Alpha:\", Lasso_Alpha_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block uses the Alpha parameter just found to apply Ridge regularization\n",
    "\n",
    "lr_1_Transformed_Lasso = Lasso(alpha = Lasso_Alpha_1)\n",
    "lr_1_Transformed_Lasso.fit(X_1_Transformed_Train_Scaled, Y_Train_1_PF)\n",
    "lr_1_Transformed_Lasso.score(X_1_Transformed_Train_Scaled, Y_Train_1_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block scores the regularized model on the test data\n",
    "\n",
    "lr_1_Transformed_Lasso.score(X_1_Transformed_Test_Scaled, Y_Test_1_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code blocks performs regression analysis on only the financial data\n",
    "# Columns indicating (by one hot encoding) which industry or sector a company is in are excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block creates a second dataframe with only the financial data and S&P weight\n",
    "\n",
    "Regression_DF_2 = Regression_DF_1.filter(['Weight', 'Total Revenue', 'Gross Profit', 'Operating Income',\n",
    "                                          'Pretax Income', 'Net Income Common Stockholders', \n",
    "                                          'Percent Increase']).copy()\n",
    "\n",
    "#display(Regression_DF_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Linear Regression without category variables\n",
    "\n",
    "X_2 = Regression_DF_2.loc[:, 'Weight':'Net Income Common Stockholders']\n",
    "\n",
    "Y_2 = Regression_DF_2['Percent Increase']\n",
    "\n",
    "X_Train_2, X_Test_2, Y_Train_2, Y_Test_2 = train_test_split(X_2, Y_2, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Linear Regression without category variables, even worse when category data is removed\n",
    "\n",
    "lr_2 = LinearRegression()\n",
    "\n",
    "lr_2.fit(X_Train_2, Y_Train_2)\n",
    "\n",
    "lr_2.score(X_Train_2, Y_Train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Test, even worse when category data is removed\n",
    "\n",
    "lr_2.score(X_Test_2, Y_Test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the coeficient array for this regression, de-commentify the line of code below\n",
    "\n",
    "#lr_2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the Y intercept array for this regression, de-commentify the line of code below\n",
    "\n",
    "#lr_2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block applies polynomial features to the second dataframe/feature set\n",
    "\n",
    "pf_2 = PolynomialFeatures(degree=2)\n",
    "\n",
    "pf_2.fit(X_2)\n",
    "\n",
    "X_2_Transformed = pf_2.transform(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block performs a test train split\n",
    "\n",
    "X_2_Transformed_Train, X_2_Transformed_Test, Y_Train_2_PF, Y_Test_2_PF = train_test_split(X_2_Transformed, Y_2, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block fits and scores a regression on the second polynomial feature set train data\n",
    "\n",
    "lr_2_Transformed = LinearRegression()\n",
    "\n",
    "lr_2_Transformed.fit(X_2_Transformed_Train, Y_Train_2_PF)\n",
    "\n",
    "lr_2_Transformed.score(X_2_Transformed_Train, Y_Train_2_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block scores the regression on the test data (prior to regularization)\n",
    "\n",
    "lr_2_Transformed.score(X_2_Transformed_Test, Y_Test_2_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code blocks applies regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block scales the features to have a mean of 0 and standard deviation of 1\n",
    "\n",
    "std = StandardScaler()\n",
    "std.fit(X_2_Transformed)\n",
    "X_2_Transformed_Train_Scaled = std.transform(X_2_Transformed_Train)\n",
    "X_2_Transformed_Test_Scaled = std.transform(X_2_Transformed_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block finds a good value for the Alpha parameter for Ridge regularization\n",
    "# To view the progress of optimizing alpha values, de-commentify the print statements\n",
    "\n",
    "Alpha = 1\n",
    "Prior_Alpha = 0\n",
    "Best_Alpha_Passed = False\n",
    "Iterations = 0\n",
    "\n",
    "Current_Test_Score = 0\n",
    "Prior_Test_Score = 0\n",
    "\n",
    "#print(\"Alpha   |      Test Score\")\n",
    "#print(\"________|________________\")\n",
    "\n",
    "while((Iterations < 2) or (Best_Alpha_Passed == False)):\n",
    "    \n",
    "    if(Iterations > 0):\n",
    "        Prior_Test_Score = Current_Test_Score\n",
    "        Prior_Alpha = Alpha\n",
    "        Alpha = (2 * Alpha)\n",
    "\n",
    "    lr_2_Transformed_Ridge = Ridge(alpha = Alpha)\n",
    "    lr_2_Transformed_Ridge.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    Train_Score = lr_2_Transformed_Ridge.score(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    \n",
    "    Current_Test_Score = lr_2_Transformed_Ridge.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)\n",
    "    \n",
    "    #print(Alpha, \":         \", Current_Test_Score)\n",
    "    \n",
    "    if(Iterations > 0):\n",
    "        if(Current_Test_Score < Prior_Test_Score):\n",
    "            Best_Alpha_Passed = True    \n",
    "            \n",
    "    Iterations += 1\n",
    "    \n",
    "Low_Alpha = max(0, ((Prior_Alpha/2) - 1))\n",
    "High_Alpha = Alpha\n",
    "Mid_Alpha = ((Low_Alpha + High_Alpha)/2)\n",
    "Increment = (High_Alpha - Mid_Alpha)\n",
    "\n",
    "while(Increment > 0.01):\n",
    "    \n",
    "    lr_2_Transformed_Ridge = Ridge(alpha = Low_Alpha)\n",
    "    lr_2_Transformed_Ridge.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    Low_Alpha_Test_Score = lr_2_Transformed_Ridge.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)\n",
    "    \n",
    "    lr_2_Transformed_Ridge = Ridge(alpha = Mid_Alpha)\n",
    "    lr_2_Transformed_Ridge.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    Mid_Alpha_Test_Score = lr_2_Transformed_Ridge.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)\n",
    "    \n",
    "    #print(Mid_Alpha, \":         \", Mid_Alpha_Test_Score)\n",
    "    \n",
    "    lr_2_Transformed_Ridge = Ridge(alpha = High_Alpha)\n",
    "    lr_2_Transformed_Ridge.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    High_Alpha_Test_Score = lr_2_Transformed_Ridge.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)\n",
    "    \n",
    "    if(High_Alpha_Test_Score > Low_Alpha_Test_Score):\n",
    "        if(High_Alpha_Test_Score <= Mid_Alpha_Test_Score):\n",
    "            Increment = (Increment/2)\n",
    "        Mid_Alpha += Increment\n",
    "    elif(High_Alpha_Test_Score < Low_Alpha_Test_Score):\n",
    "        if(Low_Alpha_Test_Score <= Mid_Alpha_Test_Score):\n",
    "            Increment = (Increment/2)\n",
    "        Mid_Alpha -= Increment\n",
    "    else:\n",
    "        Increment = (Increment/2)\n",
    "        \n",
    "    Low_Alpha = (Mid_Alpha - Increment)\n",
    "    High_Alpha = (Mid_Alpha + Increment)\n",
    "    \n",
    "Ridge_Alpha_2 = Mid_Alpha\n",
    "#print(\"________________________________\")\n",
    "#print(\"Final Ridge Alpha:\", Ridge_Alpha_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block uses the Alpha parameter just found to apply Ridge regularization\n",
    "\n",
    "lr_2_Transformed_Ridge = Ridge(alpha = Ridge_Alpha_2)\n",
    "lr_2_Transformed_Ridge.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "lr_2_Transformed_Ridge.score(X_2_Transformed_Train_Scaled, Y_Train_2_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block scores the regularized model on the test data\n",
    "\n",
    "lr_2_Transformed_Ridge.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block finds a good value for the Alpha parameter for Lasso regularization\n",
    "# To view the progress of optimizing alpha values, de-commentify the print statements\n",
    "\n",
    "Alpha = 1\n",
    "Prior_Alpha = 0\n",
    "Best_Alpha_Passed = False\n",
    "Iterations = 0\n",
    "\n",
    "Current_Test_Score = 0\n",
    "Prior_Test_Score = 0\n",
    "\n",
    "#print(\"Alpha   |      Test Score\")\n",
    "#print(\"________|________________\")\n",
    "\n",
    "while((Iterations < 2) or (Best_Alpha_Passed == False)):\n",
    "    \n",
    "    if(Iterations > 0):\n",
    "        Prior_Test_Score = Current_Test_Score\n",
    "        Prior_Alpha = Alpha\n",
    "        Alpha = (2 * Alpha)\n",
    "\n",
    "    lr_2_Transformed_Lasso = Lasso(alpha = Alpha)\n",
    "    lr_2_Transformed_Lasso.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    Train_Score = lr_2_Transformed_Lasso.score(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    \n",
    "    Current_Test_Score = lr_2_Transformed_Lasso.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)\n",
    "    \n",
    "    #print(Alpha, \":         \", Current_Test_Score)\n",
    "    \n",
    "    if(Iterations > 0):\n",
    "        if(Current_Test_Score < Prior_Test_Score):\n",
    "            Best_Alpha_Passed = True    \n",
    "            \n",
    "    Iterations += 1\n",
    "    \n",
    "Low_Alpha = max(0, ((Prior_Alpha/2) - 1))\n",
    "High_Alpha = Alpha\n",
    "Mid_Alpha = ((Low_Alpha + High_Alpha)/2)\n",
    "Increment = (High_Alpha - Mid_Alpha)\n",
    "\n",
    "while(Increment > 0.01):\n",
    "    \n",
    "    lr_2_Transformed_Lasso = Lasso(alpha = Low_Alpha)\n",
    "    lr_2_Transformed_Lasso.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    Low_Alpha_Test_Score = lr_2_Transformed_Lasso.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)\n",
    "    \n",
    "    lr_2_Transformed_Lasso = Lasso(alpha = Mid_Alpha)\n",
    "    lr_2_Transformed_Lasso.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    Mid_Alpha_Test_Score = lr_2_Transformed_Lasso.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)\n",
    "    \n",
    "    #print(Mid_Alpha, \":         \", Mid_Alpha_Test_Score)\n",
    "    \n",
    "    lr_2_Transformed_Lasso = Lasso(alpha = High_Alpha)\n",
    "    lr_2_Transformed_Lasso.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "    High_Alpha_Test_Score = lr_2_Transformed_Lasso.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)\n",
    "    \n",
    "    if(High_Alpha_Test_Score > Low_Alpha_Test_Score):\n",
    "        if(High_Alpha_Test_Score <= Mid_Alpha_Test_Score):\n",
    "            Increment = (Increment/2)\n",
    "        Mid_Alpha += Increment\n",
    "    elif(High_Alpha_Test_Score < Low_Alpha_Test_Score):\n",
    "        if(Low_Alpha_Test_Score <= Mid_Alpha_Test_Score):\n",
    "            Increment = (Increment/2)\n",
    "        Mid_Alpha -= Increment\n",
    "    else:\n",
    "        Increment = (Increment/2)\n",
    "        \n",
    "    Low_Alpha = (Mid_Alpha - Increment)\n",
    "    High_Alpha = (Mid_Alpha + Increment)\n",
    "    \n",
    "Lasso_Alpha_2 = Mid_Alpha\n",
    "#print(\"________________________________\")\n",
    "#print(\"Final Lasso Alpha:\", Lasso_Alpha_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block uses the Alpha parameter just found to apply Lasso regularization\n",
    "\n",
    "lr_2_Transformed_Lasso = Lasso(alpha = Lasso_Alpha_2)\n",
    "lr_2_Transformed_Lasso.fit(X_2_Transformed_Train_Scaled, Y_Train_2_PF)\n",
    "lr_2_Transformed_Lasso.score(X_2_Transformed_Train_Scaled, Y_Train_2_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block scoes the regularizaed model on the test data\n",
    "\n",
    "lr_2_Transformed_Lasso.score(X_2_Transformed_Test_Scaled, Y_Test_2_PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
